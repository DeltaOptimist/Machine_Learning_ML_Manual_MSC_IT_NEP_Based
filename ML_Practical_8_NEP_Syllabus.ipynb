{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wwsE8bIfidqK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_class_means(X, y, classes):\n",
        "    \"\"\"Calculate mean for each feature in each class\"\"\"\n",
        "    n_features = X.shape[1]\n",
        "    means = np.zeros((len(classes), n_features))\n",
        "\n",
        "    for idx, c in enumerate(classes):\n",
        "        means[idx] = np.mean(X[y == c], axis=0)\n",
        "    return means\n",
        "\n",
        "def calculate_class_variances(X, y, classes):\n",
        "    \"\"\"Calculate variance for each feature in each class\"\"\"\n",
        "    n_features = X.shape[1]\n",
        "    variances = np.zeros((len(classes), n_features))\n",
        "\n",
        "    for idx, c in enumerate(classes):\n",
        "        variances[idx] = np.var(X[y == c], axis=0)\n",
        "    return variances\n",
        "\n",
        "def calculate_class_priors(y, classes):\n",
        "    \"\"\"Calculate prior probabilities for each class\"\"\"\n",
        "    n_samples = len(y)\n",
        "    priors = np.zeros(len(classes))\n",
        "\n",
        "    for idx, c in enumerate(classes):\n",
        "        priors[idx] = np.sum(y == c) / float(n_samples)\n",
        "    return priors\n",
        "\n",
        "def calculate_likelihood(x, mean, variance):\n",
        "    \"\"\"Calculate likelihood using Gaussian probability density function\"\"\"\n",
        "    numerator = np.exp(-(x - mean) ** 2 / (2 * variance))\n",
        "    denominator = np.sqrt(2 * np.pi * variance)\n",
        "    return np.sum(np.log(numerator / denominator))\n",
        "\n",
        "def predict_single_sample(x, classes, means, variances, priors):\n",
        "    \"\"\"Predict class for a single sample\"\"\"\n",
        "    posteriors = []\n",
        "\n",
        "    for idx, _ in enumerate(classes):\n",
        "        prior = np.log(priors[idx])\n",
        "        likelihood = calculate_likelihood(x, means[idx], variances[idx])\n",
        "        posterior = prior + likelihood\n",
        "        posteriors.append(posterior)\n",
        "\n",
        "    return classes[np.argmax(posteriors)]\n",
        "\n",
        "def predict_samples(X, classes, means, variances, priors):\n",
        "    \"\"\"Predict classes for multiple samples\"\"\"\n",
        "    return np.array([predict_single_sample(x, classes, means, variances, priors) for x in X])\n",
        "\n"
      ],
      "metadata": {
        "id": "VChdfHOdkEeA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and prepare the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "classes = np.unique(y)\n",
        "\n"
      ],
      "metadata": {
        "id": "d2diahQrkNsc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "FDvzuAP0kP_z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model (calculate parameters)\n",
        "means = calculate_class_means(X_train_scaled, y_train, classes)\n",
        "variances = calculate_class_variances(X_train_scaled, y_train, classes)\n",
        "priors = calculate_class_priors(y_train, classes)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = predict_samples(X_test_scaled, classes, means, variances, priors)\n",
        "\n"
      ],
      "metadata": {
        "id": "hVUdgcDPkSPN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXtixG3wkTvl",
        "outputId": "b4b51298-65d5-4b6d-d840-3b6b06e022f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prediction for a single sample\n",
        "sample = X_test_scaled[0].reshape(1, -1)\n",
        "prediction = predict_samples(sample, classes, means, variances, priors)\n",
        "print(f\"\\nSample prediction: {iris.target_names[prediction[0]]}\")\n",
        "\n",
        "# Print learned parameters for each class\n",
        "print(\"\\nLearned Parameters:\")\n",
        "for i, class_name in enumerate(iris.target_names):\n",
        "    print(f\"\\nClass: {class_name}\")\n",
        "    print(f\"Mean values: {means[i]}\")\n",
        "    print(f\"Variance values: {variances[i]}\")\n",
        "    print(f\"Prior probability: {priors[i]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGpS16dDkVBt",
        "outputId": "287179cc-f031-4bf7-bcd9-a8e7f560b890"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample prediction: versicolor\n",
            "\n",
            "Learned Parameters:\n",
            "\n",
            "Class: setosa\n",
            "Mean values: [-0.99853884  0.87386315 -1.30465921 -1.25253455]\n",
            "Variance values: [0.18410123 0.76235228 0.010837   0.01955553]\n",
            "Prior probability: 0.333\n",
            "\n",
            "Class: versicolor\n",
            "Mean values: [ 0.13450779 -0.65050066  0.29500775  0.18503413]\n",
            "Variance values: [0.4263546  0.50051842 0.07416509 0.07345657]\n",
            "Prior probability: 0.342\n",
            "\n",
            "Class: virginica\n",
            "Mean values: [ 0.88273678 -0.21241023  1.02797565  1.09012776]\n",
            "Variance values: [0.61899202 0.49565077 0.09383304 0.14620106]\n",
            "Prior probability: 0.325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YX2tCguBkVWs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}